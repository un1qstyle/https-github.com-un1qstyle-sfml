{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт библиотек\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup # Превращалка html в текст.\n",
    "import pymorphy2 # Морфологический анализатор.\n",
    "from collections import Counter # Не считать же частоты самим.\n",
    "import re # Регулярные выражения.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve #импорт roc и auc roc\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "import pymorphy2 # Морфологический анализатор.\n",
    "morph=pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание функций для решения задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClass(name, descr):\n",
    "    cosname = dict.fromkeys(name.split(), 1)\n",
    "    cosdescr = dict.fromkeys(descr.split(), 1)\n",
    "\n",
    "    maxsim1 = 0\n",
    "    maxsim2 = 0\n",
    "    maxsim3 = 0\n",
    "    maxsim4 = 0\n",
    "\n",
    "    \n",
    "    for i in vt1d:\n",
    "    \n",
    "        cursim = cosineSimilarity(cosname, i)\n",
    "    \n",
    "        if maxsim1 < cursim:\n",
    "            maxsim1 = cursim\n",
    "            \n",
    "        if maxsim1==1:\n",
    "            return 1\n",
    "        \n",
    "    if maxsim1==1:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "    for i in vt2d:\n",
    "    \n",
    "        cursim = cosineSimilarity(cosname, i)\n",
    "    \n",
    "        if maxsim2 < cursim:\n",
    "            maxsim2 = cursim\n",
    "        \n",
    "        if maxsim2 >= maxsim1:\n",
    "            break\n",
    "            \n",
    "    if maxsim1 > maxsim2 or maxsim1==1:\n",
    "        return 1\n",
    "    elif maxsim1 < maxsim2 or maxsim1==0:\n",
    "        return 0\n",
    "    else:\n",
    "        \n",
    "        for i in vt3d:\n",
    "    \n",
    "            cursim = cosineSimilarity(cosdescr, i)\n",
    "    \n",
    "            if maxsim3 < cursim:\n",
    "                maxsim3 = cursim\n",
    "\n",
    "        for i in vt4d:\n",
    "    \n",
    "            cursim = cosineSimilarity(cosdescr, i)\n",
    "    \n",
    "            if maxsim4 < cursim:\n",
    "                maxsim4 = cursim\n",
    "                \n",
    "            if maxsim4 >= maxsim3:\n",
    "                break\n",
    "        \n",
    "        if maxsim3 > maxsim4:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для выделения описания должности из html-текста\n",
    "def DescHTMLtoTEXT(htmltext):\n",
    "    bs=BeautifulSoup(htmltext, \"html5lib\").body\n",
    "\n",
    "    text = BeautifulSoup(htmltext, 'lxml').get_text()\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(a, b):\n",
    "    if len(a.keys())==0 or len(b.keys())==0:\n",
    "        return 0\n",
    "    sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "    suma2=sum([a[na]*a[na] for na in a.keys()])\n",
    "    sumb2=sum([b[nb]*b[nb] for nb in b.keys()])\n",
    "    return sumab/math.sqrt(suma2*sumb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMeaningWords(string):\n",
    "    stst = ''\n",
    "    \n",
    "    tokensrus = re.findall('[А-Яа-яЁё]+', string)\n",
    "    tokenslatin = re.findall('[A-Za-z]+', string)\n",
    "    \n",
    "    for t in tokensrus:\n",
    "        if len(t) > 2:\n",
    "        \n",
    "            pv = morph.parse(t)\n",
    "            for p in pv:\n",
    "                if p.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF']:\n",
    "                    stst = stst + p.normal_form + ' '\n",
    "                    break  \n",
    "    for t in tokenslatin:\n",
    "        stst = stst + t + ' '\n",
    "    return stst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMeanDictionaries(input_dataframe):\n",
    "    t = timer()\n",
    "    #Разделение датафрейма на вакансии интересующие и неинтересующие\n",
    "    target1 = input_dataframe[input_dataframe.target==1]\n",
    "    target0 = input_dataframe[input_dataframe.target==0]\n",
    "    \n",
    "    #elapsed = timer() - t\n",
    "    #print('Target: ', elapsed)\n",
    "    #t = timer()\n",
    "        \n",
    "    #Получение всех слов в наименованиях и описаниях вакансий\n",
    "    Names_target1 = ' '.join(target1.loc[:,'name'].apply(GetMeaningWords))\n",
    "    Names_target0 = ' '.join(target0.loc[:,'name'].apply(GetMeaningWords))\n",
    "    \n",
    "    #elapsed = timer() - t\n",
    "    #print('Words: names: ', elapsed)\n",
    "    #t = timer()\n",
    "       \n",
    "    Desc_target1 = ' '.join(target1.loc[:,'description'].apply(GetMeaningWords))\n",
    "    Desc_target0 = ' '.join(target0.loc[:,'description'].apply(GetMeaningWords))\n",
    "    \n",
    "    #elapsed = timer() - t\n",
    "    #print('Words: descriptions:', elapsed)\n",
    "    #t = timer()\n",
    "    \n",
    "    #CountVectorizer для наименования вакансий\n",
    "    counter_vec    = CountVectorizer(ngram_range=(2,3))\n",
    "    analyzer       = counter_vec.build_analyzer()\n",
    "    \n",
    "    #наименования вакансий интересующих\n",
    "    if len(Names_target1) > 0:\n",
    "        result         = counter_vec.fit_transform([Names_target1])\n",
    "        words_target1  = [x[0] for x in sorted(counter_vec.vocabulary_.items(), key=lambda x: x[1])]\n",
    "        vocabulary_target1 = pd.DataFrame({'words': words_target1, 'freq': result.toarray()[0]})\n",
    "    else:\n",
    "        vocabulary_target1 = pd.DataFrame(columns=['words','freq'])\n",
    "    #vocabulary_target1 = vocabulary_target1[vocabulary_target1.freq > 3].sort_values('freq',ascending=False)\n",
    "    \n",
    "    #elapsed = timer() - t\n",
    "    #print('CountVectorizer names target=1: ', elapsed)\n",
    "    #t = timer()\n",
    "    \n",
    "    #наименования вакансий неинтересующих\n",
    "    if len(Names_target0) > 0:\n",
    "        #print(len(Names_target0), Names_target0)\n",
    "        try:\n",
    "            result         = counter_vec.fit_transform([Names_target0])\n",
    "            words_target0  = [x[0] for x in sorted(counter_vec.vocabulary_.items(), key=lambda x: x[1])]\n",
    "            vocabulary_target0 = pd.DataFrame({'words': words_target0, 'freq': result.toarray()[0]})\n",
    "        except:\n",
    "            vocabulary_target0 = pd.DataFrame(columns=['words','freq'])\n",
    "    else:\n",
    "        vocabulary_target0 = pd.DataFrame(columns=['words','freq'])\n",
    "    #vocabulary_target0 = vocabulary_target0[vocabulary_target0.freq > 3].sort_values('freq',ascending=False)\n",
    "     \n",
    "    #elapsed = timer() - t\n",
    "    #print('CountVectorizer names target=0: ', elapsed)\n",
    "    #t = timer()\n",
    "\n",
    "    #описания вакансий интересующих \n",
    "    if len(Desc_target1) > 0:\n",
    "        result  = counter_vec.fit_transform([Desc_target1])\n",
    "        words_target1_desc = [x[0] for x in sorted(counter_vec.vocabulary_.items(), key=lambda x: x[1])]\n",
    "        vocabulary_target1_desc = pd.DataFrame({'words': words_target1_desc, 'freq': result.toarray()[0]})\n",
    "    else:\n",
    "        vocabulary_target1_desc = pd.DataFrame(columns=['words','freq'])\n",
    "    #vocabulary_target1_desc = vocabulary_target1_desc[vocabulary_target1_desc.freq > 3].sort_values('freq',ascending=False)\n",
    "    \n",
    "    #elapsed = timer() - t\n",
    "    #print('CountVectorizer descriptions target=1: ', elapsed)\n",
    "    #t = timer()\n",
    "    if len(Desc_target0) > 0:\n",
    "        result  = counter_vec.fit_transform([Desc_target0])\n",
    "        words_target0_desc = [x[0] for x in sorted(counter_vec.vocabulary_.items(), key=lambda x: x[1])]\n",
    "        vocabulary_target0_desc = pd.DataFrame({'words': words_target0_desc, 'freq': result.toarray()[0]})\n",
    "    else:\n",
    "        vocabulary_target0_desc = pd.DataFrame(columns=['words','freq'])\n",
    "    #vocabulary_target0_desc = vocabulary_target0_desc[vocabulary_target0_desc.freq > 3].sort_values('freq',ascending=False)\n",
    "\n",
    "    #elapsed = timer() - t\n",
    "    #print('CountVectorizer descriptions target=0: ', elapsed)\n",
    "    #t = timer()\n",
    "\n",
    "    #Возвращаю датафреймы с колонками \"words\" и \"freq\"\n",
    "    return vocabulary_target1, vocabulary_target0, vocabulary_target1_desc, vocabulary_target0_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteSimilarWords(frame_target1, frame_target0):\n",
    "    #Удаление повторяющихся слов в словарях\n",
    "    words_vt1 = frame_target1['words']\n",
    "    words_vt2 = frame_target0['words']\n",
    "    words2list = words_vt2.tolist()\n",
    "\n",
    "    for index1, word in enumerate(words_vt1):\n",
    "        if word in words2list:\n",
    "            frame_target1 = frame_target1.drop([words_vt1.index[index1]])\n",
    "            for index2, word2 in enumerate(words_vt2):\n",
    "                if word == word2:\n",
    "                    frame_target0 = frame_target0.drop(words_vt2.index[index2])\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDict(v1,v2,v3,v4):\n",
    "    #не списки, а словари, для измерения косинусовых расстояний\n",
    "    vt1d = []\n",
    "    for i in v1:\n",
    "        ii = i.split()\n",
    "        vt1d.append(dict.fromkeys(ii,1))\n",
    "    \n",
    "    vt2d = []\n",
    "    for i in v2:\n",
    "        ii = i.split()\n",
    "        vt2d.append(dict.fromkeys(ii,1))\n",
    "    \n",
    "    vt3d = []\n",
    "    for i in v3:\n",
    "        ii = i.split()\n",
    "        vt3d.append(dict.fromkeys(ii,1))\n",
    "    \n",
    "    vt4d = []\n",
    "    for i in v4:\n",
    "        ii = i.split()\n",
    "        vt4d.append(dict.fromkeys(ii,1))\n",
    "                    \n",
    "    return vt1d, vt2d, vt3d, vt4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь начинается решение задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение файла\n",
    "dataframe = pd.read_csv('train.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#порционное получение словарей\n",
    "Names_target1_vocabulary = pd.DataFrame(columns=['words','freq'])\n",
    "Names_target0_vocabulary = pd.DataFrame(columns=['words','freq'])\n",
    "Descr_target1_vocabulary = pd.DataFrame(columns=['words','freq'])\n",
    "Descr_target0_vocabulary = pd.DataFrame(columns=['words','freq'])\n",
    "\n",
    "try:\n",
    "    protokol_file = open('protokol.txt', 'r')\n",
    "    asd = protokol_file.read()\n",
    "    listsrt = asd.split('\\n')\n",
    "\n",
    "    start = int(listsrt[len(listsrt)-2])\n",
    "    protokol_file.close()\n",
    "except:\n",
    "    start = 0\n",
    "\n",
    "for i in range(start, len(dataframe), 1000):\n",
    "    portion = dataframe.loc[i:i+999,:].copy()\n",
    "    portion['description'] = portion['description'].map(DescHTMLtoTEXT) #по части\n",
    "    \n",
    "    n1,n0,d1,d0 = GetMeanDictionaries(portion)\n",
    "    \n",
    "    Names_target1_vocabulary = pd.concat([Names_target1_vocabulary, n1])\n",
    "    Names_target0_vocabulary = pd.concat([Names_target0_vocabulary, n0])\n",
    "    Descr_target1_vocabulary = pd.concat([Descr_target1_vocabulary, d1])\n",
    "    Descr_target0_vocabulary = pd.concat([Descr_target0_vocabulary, d0])\n",
    "\n",
    "    Names_target1_vocabulary.to_csv('Names_target1.csv', index = False)\n",
    "    Names_target0_vocabulary.to_csv('Names_target0.csv', index = False)\n",
    "    Descr_target1_vocabulary.to_csv('Descr_target1.csv', index = False)\n",
    "    Descr_target0_vocabulary.to_csv('Descr_target0.csv', index = False)\n",
    "    \n",
    "    protokol_file = open('protokol.txt', 'w')\n",
    "    protokol_file.write(str(i+99))\n",
    "    protokol_file.write('\\n')   \n",
    "    protokol_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение из собранного ранее словаря\n",
    "vt1 = pd.read_csv('Names_target1.csv')\n",
    "vt1 = vt1.groupby('words').sum()\n",
    "vt1 = vt1[vt1.freq > 20]\n",
    "vt1.reset_index(inplace=True)\n",
    "\n",
    "vt2 = pd.read_csv('Names_target0.csv')\n",
    "vt2 = vt2.groupby('words').sum()\n",
    "vt2 = vt2[vt2.freq > 20]\n",
    "vt2.reset_index(inplace=True)\n",
    "\n",
    "vt3 = pd.read_csv('Descr_target1.csv')\n",
    "vt3 = vt3.groupby('words').sum()\n",
    "vt3 = vt3[vt3.freq > 20]\n",
    "vt3.reset_index(inplace=True)\n",
    "\n",
    "vt4 = pd.read_csv('Descr_target0.csv')\n",
    "vt4 = vt4.groupby('words').sum()\n",
    "vt4 = vt4[vt4.freq > 20]\n",
    "vt4.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt1d, vt2d, vt3d, vt4d = toDict(vt1['words'].tolist(),vt2['words'].tolist(),vt3['words'].tolist(),vt4['words'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка тестовой выборки\n",
    "testdf =  dataframe.loc[0:100,:].copy() #Для отладки, чтобы не ждать по 15 минут\n",
    "#testdf = dataframe_less.copy()\n",
    "testdf['description'] = testdf['description'].map(DescHTMLtoTEXT) #по части\n",
    "\n",
    "testdf['name1'] = testdf['name'].apply(lambda x: ' '.join(a[0] for a in re.findall(\"([А-ЯЁа-яёA-Za-z]+(-[А-ЯЁа-яёA-Za-z]+)*)\", x)))\n",
    "testdf['name1'] = testdf['name'].map(GetMeaningWords)\n",
    "testdf['description1'] = testdf['description'].map(GetMeaningWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Предсказание \n",
    "testdf['newtarget'] = testdf.apply(lambda x: GetClassNew(x['name1'], x['description1']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc модели DecisionTreeClassifier 0.6436758893280632\n",
      "(101, 7)\n"
     ]
    }
   ],
   "source": [
    "#подсчет roc_auc_score\n",
    "print('roc_auc модели ', roc_auc_score(testdf['target'], testdf['newtarget']))\n",
    "print (testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative: (1, 7)\n",
      "False positive: (38, 7)\n"
     ]
    }
   ],
   "source": [
    "#для анализа ошибок модели\n",
    "print('False negative:', testdf[(testdf.target!=testdf.newtarget) & (testdf.newtarget==0)].shape)\n",
    "print('False positive:', testdf[(testdf.target!=testdf.newtarget) & (testdf.newtarget==1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>target</th>\n",
       "      <th>name1</th>\n",
       "      <th>description1</th>\n",
       "      <th>newtarget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>Бариста</td>\n",
       "      <td>Мы предлагаем:  Место работы: уютное кафе м. \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>барист</td>\n",
       "      <td>предлагать место работа уютный кафе метр курск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     name                                        description  target  \\\n",
       "64  64  Бариста  Мы предлагаем:  Место работы: уютное кафе м. \"...       1   \n",
       "\n",
       "      name1                                       description1  newtarget  \n",
       "64  барист   предлагать место работа уютный кафе метр курск...          0  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = testdf[(testdf.target!=testdf.newtarget) & (testdf.newtarget==0)]\n",
    "#GetClass(errors['name1'][8], errors['description1'][8])\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение файла\n",
    "dataframe_test = pd.read_csv('test.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test['description'] = dataframe_test['description'].map(DescHTMLtoTEXT) #по части\n",
    "\n",
    "dataframe_test['name1'] = dataframe_test['name'].apply(lambda x: ' '.join(a[0] for a in re.findall(\"([А-ЯЁа-яёA-Za-z]+(-[А-ЯЁа-яёA-Za-z]+)*)\", x)))\n",
    "dataframe_test['name1'] = dataframe_test['name'].map(GetMeaningWords)\n",
    "dataframe_test['description1'] = dataframe_test['description'].map(GetMeaningWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test.to_csv('norm.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.read_csv('norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = dataframe_test.fillna(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gavrilov_ej\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\gavrilov_ej\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF = pd.DataFrame(columns = ['id', 'target'])\n",
    "\n",
    "try:\n",
    "    protokol_file = open('protokol.txt', 'r')\n",
    "    asd = protokol_file.read()\n",
    "    listsrt = asd.split('\\n')\n",
    "\n",
    "    start = int(listsrt[len(listsrt)-2]) +1\n",
    "    protokol_file.close()\n",
    "except:\n",
    "    start = 0\n",
    "\n",
    "for i in range(start, 130000, 500):\n",
    "    dataframe_test_portion = dataframe_test.loc[i:i+499,:]\n",
    "    dataframe_test_portion['target'] = dataframe_test_portion.apply(lambda x: GetClass(x['name1'], x['description1']), axis = 1)\n",
    "    \n",
    "    resultDF = pd.concat([resultDF, dataframe_test_portion])\n",
    "    resultDF.to_csv('predict.csv', index=None,columns=['id','name','target'])\n",
    "    protokol_file = open('protokol.txt', 'w')\n",
    "    protokol_file.write(str(i+499))\n",
    "    protokol_file.write('\\n')   \n",
    "    protokol_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
